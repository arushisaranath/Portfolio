{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get data in and set up X_train, X_test, y_train objects"
      ],
      "metadata": {
        "id": "hR8Tr8CV4_FO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install aimodelshare library\n",
        "! pip install aimodelshare==0.0.189"
      ],
      "metadata": {
        "id": "HMslfPQQ5BpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get competition data\n",
        "from aimodelshare import download_data\n",
        "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F2Qiaac4mjo",
        "outputId": "6144352a-a9c0-4e57-bc7b-bdd5860be89a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [=============================================>   ]\n",
            "\n",
            "Data downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up X_train, X_test, and y_train_labels objects\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=Warning)\n",
        "\n",
        "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
        "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
        "\n",
        "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
        "\n",
        "# ohe encode Y data\n",
        "y_train = pd.get_dummies(y_train_labels)\n",
        "\n",
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTCdQ-Ip4o2P",
        "outputId": "2bc5b566-b784-4d27-cbb8-2625340aaf24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    The Rock is destined to be the 21st Century 's...\n",
              "1    The gorgeously elaborate continuation of `` Th...\n",
              "2    Singer/composer Bryan Adams contributes a slew...\n",
              "3                 Yet the act is still charming here .\n",
              "4    Whether or not you 're enlightened by any of D...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head(n=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNZQvnAYIAhO",
        "outputId": "c777059a-1dcb-4777-830f-d9e0cb3de8bc"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     The Rock is destined to be the 21st Century 's...\n",
              "1     The gorgeously elaborate continuation of `` Th...\n",
              "2     Singer/composer Bryan Adams contributes a slew...\n",
              "3                  Yet the act is still charming here .\n",
              "4     Whether or not you 're enlightened by any of D...\n",
              "5     Just the labour involved in creating the layer...\n",
              "6     Part of the charm of Satin Rouge is that it av...\n",
              "7     a screenplay more ingeniously constructed than...\n",
              "8              `` Extreme Ops '' exceeds expectations .\n",
              "9     Good fun , good action , good acting , good di...\n",
              "10                     Dramas like this make it human .\n",
              "11    Still , this flick is fun , and host to some t...\n",
              "12    Australian actor/director John Polson and awar...\n",
              "13    You walk out of The Good Girl with mixed emoti...\n",
              "14          Absorbing character study by André Turpin .\n",
              "15    If you love reading and/or poetry , then by al...\n",
              "16                           You 'll probably love it .\n",
              "17    `` Frailty '' has been written so well , that ...\n",
              "18    Grenier is terrific , bringing an unforced , r...\n",
              "19                           The actors are fantastic .\n",
              "20    They are what makes it worth the trip to the t...\n",
              "21    ( Taymor ) utilizes the idea of making Kahlo '...\n",
              "22                             This is n't a new idea .\n",
              "23    It 's been done before but never so vividly or...\n",
              "24    ( `` Take Care of My Cat '' ) is an honestly n...\n",
              "25    What `` Empire '' lacks in depth it makes up f...\n",
              "26    Light , silly , photographed with colour and d...\n",
              "27    But tongue-in-cheek preposterousness has alway...\n",
              "28    Much of the movie 's charm lies in the utter c...\n",
              "29    Their computer-animated faces are very express...\n",
              "30    ... spiced with humor ( ' I speak fluent flatu...\n",
              "31            There 's an energy to Y Tu Mamá También .\n",
              "32    Much of it comes from the brave , uninhibited ...\n",
              "33    `` Auto Focus '' works as an unusual biopic an...\n",
              "34    ... a sour little movie at its core ; an explo...\n",
              "35    feeling to it , but like the 1920 's , the tri...\n",
              "36    `` Cremaster 3 '' should come with the warning...\n",
              "37    Made me unintentionally famous -- as the queas...\n",
              "38    But believe it or not , it 's one of the most ...\n",
              "39    García Bernal and Talancón are an immensely ap...\n",
              "40    ... a spoof comedy that carries its share of l...\n",
              "41    ( City ) reminds us how realistically nuanced ...\n",
              "42    The wanton slipperiness of * Corpus and its am...\n",
              "43    `` Frailty '' starts out like a typical Bible ...\n",
              "44    For those who pride themselves on sophisticate...\n",
              "45    It cuts to the core of what it actually means ...\n",
              "46    A welcome relief from baseball movies that try...\n",
              "47    A crisp psychological drama ( and ) a fascinat...\n",
              "48    It has more than a few moments that are insigh...\n",
              "49    An uncluttered , resonant gem that relays its ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCxtWmCn9l3E",
        "outputId": "4eed3c87-7a10-4693-f963-909d6315c90c"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Positive\n",
              "1       Positive\n",
              "2       Positive\n",
              "3       Positive\n",
              "4       Positive\n",
              "          ...   \n",
              "6915    Negative\n",
              "6916    Negative\n",
              "6917    Positive\n",
              "6918    Negative\n",
              "6919    Negative\n",
              "Name: label, Length: 6920, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This preprocessor function makes use of the tf.keras tokenizer\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Build vocabulary from training text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# preprocessor tokenizes words and makes sure all documents have the same length\n",
        "def preprocessor(data, maxlen=40, max_words=10000):\n",
        "\n",
        "    sequences = tokenizer.texts_to_sequences(data)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    X = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "    return X\n",
        "\n",
        "print(preprocessor(X_train).shape)\n",
        "print(preprocessor(X_test).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SYc5XJs4rTX",
        "outputId": "55299f99-3abe-4871-85f1-90ce9777dd0d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6920, 40)\n",
            "(1821, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding,Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 16, input_length=40))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mst7q-PV5NHU",
        "outputId": "aedab68c-dd1f-4281-aeb2-49dadbfe2c07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 40, 16)            160000    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 640)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 1282      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 161,282\n",
            "Trainable params: 161,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "173/173 [==============================] - 2s 7ms/step - loss: 0.6664 - acc: 0.6134 - val_loss: 0.8460 - val_acc: 0.1488\n",
            "Epoch 2/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.6157 - acc: 0.6358 - val_loss: 0.7999 - val_acc: 0.2673\n",
            "Epoch 3/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.5186 - acc: 0.7617 - val_loss: 0.7322 - val_acc: 0.4877\n",
            "Epoch 4/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.4107 - acc: 0.8515 - val_loss: 0.7079 - val_acc: 0.5419\n",
            "Epoch 5/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.3174 - acc: 0.9046 - val_loss: 0.6523 - val_acc: 0.6344\n",
            "Epoch 6/10\n",
            "173/173 [==============================] - 1s 6ms/step - loss: 0.2443 - acc: 0.9296 - val_loss: 0.6352 - val_acc: 0.6676\n",
            "Epoch 7/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.1873 - acc: 0.9514 - val_loss: 0.5477 - val_acc: 0.7471\n",
            "Epoch 8/10\n",
            "173/173 [==============================] - 1s 5ms/step - loss: 0.1437 - acc: 0.9637 - val_loss: 0.5765 - val_acc: 0.7312\n",
            "Epoch 9/10\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.1107 - acc: 0.9736 - val_loss: 0.5827 - val_acc: 0.7319\n",
            "Epoch 10/10\n",
            "173/173 [==============================] - 1s 4ms/step - loss: 0.0848 - acc: 0.9825 - val_loss: 0.5951 - val_acc: 0.7406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save preprocessor function to local \"preprocessor.zip\" file"
      ],
      "metadata": {
        "id": "Cs1yQILd5SzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "ai.export_preprocessor(preprocessor,\"\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLNjs1Sc5YGr",
        "outputId": "f9580752-f49a-4d51-a737-19a993229f44"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your preprocessor is now saved to 'preprocessor.zip'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save model to local \".onnx\" file"
      ],
      "metadata": {
        "id": "VqdQt0555Ypr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "UiqCRI1n5dPB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set credentials using modelshare.org username/password\n",
        "\n",
        "from aimodelshare.aws import set_credentials\n",
        "    \n",
        "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
        "\n",
        "set_credentials(apiurl=apiurl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cTC9twj5l4q",
        "outputId": "13ea19f9-2457-4275-82cb-89f5bda39b99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI Modelshare Username:··········\n",
            "AI Modelshare Password:··········\n",
            "AI Model Share login credentials set successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instantiate Competition\n",
        "\n",
        "mycompetition= ai.Competition(apiurl)"
      ],
      "metadata": {
        "id": "Id5LcyRS5oYz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 1: \n",
        "\n",
        "#-- Generate predicted y values (Model 1)\n",
        "#Note: Keras predict returns the predicted column index location for classification models\n",
        "prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "WJK1sbga5rxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model has been submitted as model version 206"
      ],
      "metadata": {
        "id": "Cen5u0Ot6FPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(10000, 16, input_length=40))\n",
        "model2.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "model2.add(LSTM(32, dropout=0.2))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model2.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8mUHkdx54xB",
        "outputId": "2e486b51-862a-4bea-a31b-6865905d5e89"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 15s 61ms/step - loss: 0.6509 - acc: 0.6223 - val_loss: 0.7782 - val_acc: 0.4292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(model2, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"model2.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "CjEzFYF4573C"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 2: \n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "prediction_column_index=model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "Hm22ambj5-td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model has been submitted as model version 214"
      ],
      "metadata": {
        "id": "vtRua0Hm6B8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare two or more models \n",
        "data=mycompetition.compare_models([1, 2], verbose=1)\n",
        "mycompetition.stylize_compare(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "pzGLTFj36I5O",
        "outputId": "32925ff8-43fc-4f2f-a552-13610a9ba656"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4dc50 caption {\n",
              "  color: black;\n",
              "  font-size: 18px;\n",
              "}\n",
              "#T_4dc50_row0_col0, #T_4dc50_row0_col3 {\n",
              "  background: #b3e2cd;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_4dc50_row0_col1, #T_4dc50_row0_col2, #T_4dc50_row0_col4, #T_4dc50_row0_col5, #T_4dc50_row1_col1, #T_4dc50_row1_col2, #T_4dc50_row1_col4, #T_4dc50_row1_col5, #T_4dc50_row2_col1, #T_4dc50_row2_col2, #T_4dc50_row2_col4, #T_4dc50_row2_col5, #T_4dc50_row3_col0, #T_4dc50_row3_col1, #T_4dc50_row3_col2, #T_4dc50_row3_col4, #T_4dc50_row3_col5, #T_4dc50_row4_col0, #T_4dc50_row4_col1, #T_4dc50_row4_col2, #T_4dc50_row4_col4, #T_4dc50_row4_col5 {\n",
              "  background: white;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_4dc50_row1_col0, #T_4dc50_row3_col3 {\n",
              "  background: nan;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_4dc50_row1_col3, #T_4dc50_row2_col3 {\n",
              "  background: #f1e2cc;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "#T_4dc50_row2_col0, #T_4dc50_row4_col3 {\n",
              "  background: #fff2ae;\n",
              "  color: black;\n",
              "  color: black;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4dc50\">\n",
              "  <caption>Model type: Neural Network</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4dc50_level0_col0\" class=\"col_heading level0 col0\" >Model_1_Layer</th>\n",
              "      <th id=\"T_4dc50_level0_col1\" class=\"col_heading level0 col1\" >Model_1_Shape</th>\n",
              "      <th id=\"T_4dc50_level0_col2\" class=\"col_heading level0 col2\" >Model_1_Params</th>\n",
              "      <th id=\"T_4dc50_level0_col3\" class=\"col_heading level0 col3\" >Model_2_Layer</th>\n",
              "      <th id=\"T_4dc50_level0_col4\" class=\"col_heading level0 col4\" >Model_2_Shape</th>\n",
              "      <th id=\"T_4dc50_level0_col5\" class=\"col_heading level0 col5\" >Model_2_Params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4dc50_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_4dc50_row0_col0\" class=\"data row0 col0\" >Embedding</td>\n",
              "      <td id=\"T_4dc50_row0_col1\" class=\"data row0 col1\" >[None, 40, 16]</td>\n",
              "      <td id=\"T_4dc50_row0_col2\" class=\"data row0 col2\" >160000.000000</td>\n",
              "      <td id=\"T_4dc50_row0_col3\" class=\"data row0 col3\" >Embedding</td>\n",
              "      <td id=\"T_4dc50_row0_col4\" class=\"data row0 col4\" >[None, 40, 16]</td>\n",
              "      <td id=\"T_4dc50_row0_col5\" class=\"data row0 col5\" >160000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4dc50_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_4dc50_row1_col0\" class=\"data row1 col0\" >Flatten</td>\n",
              "      <td id=\"T_4dc50_row1_col1\" class=\"data row1 col1\" >[None, 640]</td>\n",
              "      <td id=\"T_4dc50_row1_col2\" class=\"data row1 col2\" >0.000000</td>\n",
              "      <td id=\"T_4dc50_row1_col3\" class=\"data row1 col3\" >LSTM</td>\n",
              "      <td id=\"T_4dc50_row1_col4\" class=\"data row1 col4\" >[None, 40, 32]</td>\n",
              "      <td id=\"T_4dc50_row1_col5\" class=\"data row1 col5\" >6272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4dc50_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_4dc50_row2_col0\" class=\"data row2 col0\" >Dense</td>\n",
              "      <td id=\"T_4dc50_row2_col1\" class=\"data row2 col1\" >[None, 2]</td>\n",
              "      <td id=\"T_4dc50_row2_col2\" class=\"data row2 col2\" >1282.000000</td>\n",
              "      <td id=\"T_4dc50_row2_col3\" class=\"data row2 col3\" >LSTM</td>\n",
              "      <td id=\"T_4dc50_row2_col4\" class=\"data row2 col4\" >[None, 32]</td>\n",
              "      <td id=\"T_4dc50_row2_col5\" class=\"data row2 col5\" >8320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4dc50_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_4dc50_row3_col0\" class=\"data row3 col0\" >None</td>\n",
              "      <td id=\"T_4dc50_row3_col1\" class=\"data row3 col1\" >None</td>\n",
              "      <td id=\"T_4dc50_row3_col2\" class=\"data row3 col2\" >nan</td>\n",
              "      <td id=\"T_4dc50_row3_col3\" class=\"data row3 col3\" >Flatten</td>\n",
              "      <td id=\"T_4dc50_row3_col4\" class=\"data row3 col4\" >[None, 32]</td>\n",
              "      <td id=\"T_4dc50_row3_col5\" class=\"data row3 col5\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4dc50_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_4dc50_row4_col0\" class=\"data row4 col0\" >None</td>\n",
              "      <td id=\"T_4dc50_row4_col1\" class=\"data row4 col1\" >None</td>\n",
              "      <td id=\"T_4dc50_row4_col2\" class=\"data row4 col2\" >nan</td>\n",
              "      <td id=\"T_4dc50_row4_col3\" class=\"data row4 col3\" >Dense</td>\n",
              "      <td id=\"T_4dc50_row4_col4\" class=\"data row4 col4\" >[None, 2]</td>\n",
              "      <td id=\"T_4dc50_row4_col5\" class=\"data row4 col5\" >66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Tune model within range of hyperparameters with Keras Tuner"
      ],
      "metadata": {
        "id": "YqN-KuqD6M2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2QgOrKx6SZ8",
        "outputId": "5658266c-b1df-471d-a8a8-2270bc7ccf2f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.3.5-py3-none-any.whl (176 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (23.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.3.5 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate validation data \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
        "     X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lgbAEXJK6Yyt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "import keras_tuner as kt\n",
        "\n",
        "#Define model structure & parameter search space with function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Embedding(10000, 16, input_length=40))\n",
        "    model.add(LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), #range 32-512 inclusive, minimum step between tested values is 32\n",
        "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "#initialize the tuner (which will search through parameters)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model, \n",
        "    objective=\"val_accuracy\", # objective to optimize\n",
        "    max_trials=3, #max number of trials to run during search\n",
        "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
        "    overwrite=True,\n",
        "    directory=\"tuning_model\",\n",
        "    project_name=\"tuning_units\",\n",
        ")\n",
        "\n",
        "tuner.search(preprocessor(x_train_split), y_train_split, epochs=1, validation_data=(preprocessor(x_val), y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzu5JP086bpO",
        "outputId": "3d434bf5-4caa-42d0-c043-97516cc3a7ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 02m 26s]\n",
            "val_accuracy: 0.6488439440727234\n",
            "\n",
            "Best val_accuracy So Far: 0.6683526039123535\n",
            "Total elapsed time: 00h 03m 02s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with best hyperparameters\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "tuned_model = build_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "tuned_model.fit(x=preprocessor(X_train), y=y_train, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r61Yopur6fv-",
        "outputId": "16846ae5-4cf4-4853-e7e7-1b2e02205495"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217/217 [==============================] - 33s 114ms/step - loss: 0.6691 - accuracy: 0.5789\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f58ee8d9250>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_model = model_to_onnx(tuned_model, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"tuned_model.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "6TgWGj2j6iC8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model 3: \n",
        "\n",
        "#-- Generate predicted y values (Model 3)\n",
        "prediction_column_index=tuned_model.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"tuned_model.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "i3PXDKzz6klV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model has been submitted as model version 216\n"
      ],
      "metadata": {
        "id": "1uULbGTj6m39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard\n",
        "\n",
        "data = mycompetition.get_leaderboard()\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "nB3zEz9x6rJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Models"
      ],
      "metadata": {
        "id": "vWpJ6X3g8yQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset has positive and negative labels assigned to sentences extracted from movie reviews based on the sentiment/ words/ language of the sentences/reviews. The data is split into training and testing datasets,X_train, X_test, y train, ytest to develop the model.\n",
        "\n",
        "A predictive model will automatically segregate positive and negative movie reviews using sentiment analysis. It is faster and more efficient which saves time and money.\n",
        "\n",
        "Once the model learns when reviews\\ classify as positive or negative, it reduces a lot of work for organisations that primarily work in the film industry like give movie scores eg. rotten tomatoes. If they know whether a movie has more positive or negative reviews, it becomes easier to score them and leave a final review. "
      ],
      "metadata": {
        "id": "47lNcRxj9APG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model I 5 LSTM layers"
      ],
      "metadata": {
        "id": "iaNjc2UT9V6-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "modelI = Sequential()\n",
        "modelI.add(Embedding(10000, 16, input_length=40))\n",
        "modelI.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "modelI.add(LSTM(32, return_sequences=True))\n",
        "modelI.add(LSTM(32, return_sequences=True))\n",
        "modelI.add(LSTM(32, return_sequences=True))\n",
        "modelI.add(LSTM(32, dropout=0.2))\n",
        "modelI.add(Flatten())\n",
        "modelI.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelI.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = modelI.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xQMsBOZ-z6v",
        "outputId": "385b0da2-2668-4fb6-c6fd-bebb4a763248"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 31s 120ms/step - loss: 0.6658 - acc: 0.6134 - val_loss: 0.8745 - val_acc: 0.1611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelI = model_to_onnx(modelI, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelI.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "393XJ9ky-0Ye"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model I: \n",
        "\n",
        "#-- Generate predicted  values \n",
        "prediction_column_index=modelI.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model I to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelI.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "id": "kcXmvmL_mk4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model has been submitted as model version 402"
      ],
      "metadata": {
        "id": "Ljak1cSdLMmA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model II 6 conv 1d layers"
      ],
      "metadata": {
        "id": "YlS64xcXC8hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use 1D Conv layer rather than RNN or LSTM or GRU to fit model\n",
        "# Why? Much lighter model to fit. Here we are training on the full dataset.  If you try\n",
        "# to build a model using LSTM code after running this one it will be much slower.\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import SimpleRNN, LSTM,Embedding\n",
        "\n",
        "modelII = Sequential()\n",
        "modelII.add(Embedding(10000, 16, input_length=40))\n",
        "modelII.add(layers.Conv1D(64, 2, activation='relu')) \n",
        "modelII.add(layers.Conv1D(64, 2, activation='relu')) \n",
        "modelII.add(layers.Conv1D(32, 2, activation='relu'))\n",
        "modelII.add(layers.Conv1D(32, 2, activation='relu'))  \n",
        "modelII.add(layers.MaxPooling1D(2))\n",
        "modelII.add(layers.Conv1D(16, 2, activation='relu')) \n",
        "modelII.add(layers.Conv1D(16, 2, activation='relu')) \n",
        "modelII.add(layers.GlobalAveragePooling1D())\n",
        "modelII.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelII.summary()\n"
      ],
      "metadata": {
        "id": "L_pE4yjkDBei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelII.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = modelII.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=1,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4I12N8PI1FV",
        "outputId": "a000311f-b68a-450e-dd19-1f359f946805"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 5s 20ms/step - loss: 0.6677 - acc: 0.6149 - val_loss: 0.8862 - val_acc: 0.1488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelII = model_to_onnx(modelII, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelII.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_model.SerializeToString())"
      ],
      "metadata": {
        "id": "cBHTxh6xHkDO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model II: \n",
        "\n",
        "#-- Generate predicted y values (Model 2)\n",
        "prediction_column_index=modelII.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelII.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29j9k1TdHp7K",
        "outputId": "3e947ae1-cbad-4ea4-f0c6-e5c7f8fcbb2a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 8ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 405\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your model has been submitted as model version 405"
      ],
      "metadata": {
        "id": "4bgi6vl_LPn6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model III"
      ],
      "metadata": {
        "id": "HCCib3aALSdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Glove embedding matrix weights \n",
        "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VleYodAELVw0",
        "outputId": "a6df7dcc-95fe-438a-c4c6-74521404530a"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-18 17:10:30--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-18 17:10:31--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2023-04-18 17:10:31--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  4.88MB/s    in 2m 44s  \n",
            "\n",
            "2023-04-18 17:13:16 (5.01 MB/s) - ‘glove.6B.zip.1’ saved [862182753/862182753]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip glove.6B.zip "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDs-szaMMd4c",
        "outputId": "21520eea-bcfd-4670-e065-62348c123a4e"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Extract embedding data for 100 feature embedding matrix\n",
        "glove_dir = os.getcwd()\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Glnd3aECMhA8",
        "outputId": "46580853-3d61-4a4e-f1ac-acd5a5d5b59f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400001 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build embedding matrix\n",
        "embedding_dim = 100 \n",
        "max_words = 10000 \n",
        "word_index = tokenizer.word_index\n",
        "maxlen=40\n",
        "sequences = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if i < max_words:\n",
        "        if embedding_vector is not None:\n",
        "            # Words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "dLLTq8--ZlkQ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
        "modelIII = Sequential()\n",
        "modelIII.add(Embedding(max_words, embedding_dim,  input_length=maxlen))\n",
        "modelIII.add(layers.Conv1D(64, 2, activation='relu')) \n",
        "modelIII.add(layers.Conv1D(64, 2, activation='relu')) \n",
        "modelIII.add(layers.Conv1D(32, 2, activation='relu'))\n",
        "modelIII.add(layers.Conv1D(32, 2, activation='relu'))  \n",
        "modelIII.add(layers.MaxPooling1D(2))\n",
        "modelIII.add(layers.Conv1D(16, 2, activation='relu')) \n",
        "modelIII.add(layers.Conv1D(16, 2, activation='relu')) \n",
        "modelIII.add(layers.GlobalAveragePooling1D())\n",
        "modelIII.add(Dense(2, activation='softmax'))\n",
        "\n"
      ],
      "metadata": {
        "id": "es1K44sXMzHO"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_dUxdhHYINz",
        "outputId": "7042bbf1-f25f-408b-81dc-0703db593798"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.038194  , -0.24487001,  0.72812003, ..., -0.1459    ,\n",
              "         0.82779998,  0.27061999],\n",
              "       [-0.27085999,  0.044006  , -0.02026   , ..., -0.4923    ,\n",
              "         0.63687003,  0.23642001],\n",
              "       ...,\n",
              "       [ 0.0075511 ,  0.068286  ,  0.51406997, ..., -0.6893    ,\n",
              "         0.13776   ,  0.15468   ],\n",
              "       [ 0.58331001,  0.76283997, -0.29846001, ..., -0.14741001,\n",
              "         0.34698999,  0.26282999],\n",
              "       [-0.060389  ,  0.59951001,  0.26980001, ...,  0.65445   ,\n",
              "        -0.74105   ,  0.57037002]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
        "modelIII.layers[0].set_weights([embedding_matrix])\n",
        "modelIII.layers[0].trainable = False\n",
        "\n",
        "\n",
        "\n",
        "modelIII.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "8sCarX3DM4ft"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelIII.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.01)\n",
        "modelIII.save_weights('pre_trained_glove_model.h5')\n",
        "\n",
        "\n",
        "# Training data small to speed up training. Increase for better fit."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOHiblxfaXvO",
        "outputId": "d531c8e9-6b3d-4c54-c994-aac84919f378"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "215/215 [==============================] - 5s 21ms/step - loss: 0.3313 - acc: 0.8600 - val_loss: 0.5351 - val_acc: 0.7429\n",
            "Epoch 2/10\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.3027 - acc: 0.8727 - val_loss: 0.3406 - val_acc: 0.8714\n",
            "Epoch 3/10\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.2805 - acc: 0.8838 - val_loss: 0.3504 - val_acc: 0.8714\n",
            "Epoch 4/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2501 - acc: 0.8952 - val_loss: 0.3352 - val_acc: 0.8857\n",
            "Epoch 5/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.2281 - acc: 0.9089 - val_loss: 0.3196 - val_acc: 0.9286\n",
            "Epoch 6/10\n",
            "215/215 [==============================] - 4s 18ms/step - loss: 0.2080 - acc: 0.9159 - val_loss: 0.3871 - val_acc: 0.8429\n",
            "Epoch 7/10\n",
            "215/215 [==============================] - 5s 22ms/step - loss: 0.1779 - acc: 0.9279 - val_loss: 0.5771 - val_acc: 0.7143\n",
            "Epoch 8/10\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.1670 - acc: 0.9350 - val_loss: 0.8976 - val_acc: 0.7286\n",
            "Epoch 9/10\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.1484 - acc: 0.9435 - val_loss: 0.3298 - val_acc: 0.8714\n",
            "Epoch 10/10\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.1295 - acc: 0.9512 - val_loss: 0.5993 - val_acc: 0.8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelIII = model_to_onnx(modelIII, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelIII.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_modelIII.SerializeToString())"
      ],
      "metadata": {
        "id": "JvHbhd89Ns--"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model III: \n",
        "\n",
        "#-- Generate predicted y values.\n",
        "prediction_column_index=modelIII.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelIII.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmTFzFiXa41E",
        "outputId": "87f6eab7-1be4-42a7-9adb-fb88f0b54db9"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 1s 9ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): \n",
            "\n",
            "Your model has been submitted as model version 432\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Your model has been submitted as model version 426, 425 "
      ],
      "metadata": {
        "id": "S_zFSc23cGnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard\n",
        "\n",
        "data = mycompetition.get_leaderboard()\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "MwG8XegLcXHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## My best model was the one in which I used transfer learning with glove embeddings. I applied these weights on the conv 1 d model which had 2 layers of 64 neurons, 2 layers of 32 neurons and eventually 2 layers of 16 neurons. I ran 10 epochs, had a batch_size=32,validation_split=0.01, optimizer='rmsprop' and had an accuracy of 79.69%, an f-1 score of79.66%,, precision of 79.89% and recall of 79.70%"
      ],
      "metadata": {
        "id": "W5-kePnSeClH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model IV- LSTM with 20 epochs, validation_split=0.001 with tuning to get best hyperparameters."
      ],
      "metadata": {
        "id": "d-ihRvnRku7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "modelIV = Sequential()\n",
        "modelIV.add(Embedding(10000, 16, input_length=40))\n",
        "modelIV.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
        "modelIV.add(LSTM(32, return_sequences=True))\n",
        "modelIV.add(LSTM(32, return_sequences=True))\n",
        "modelIV.add(LSTM(32, return_sequences=True))\n",
        "modelIV.add(LSTM(32, dropout=0.2))\n",
        "modelIV.add(Flatten())\n",
        "modelIV.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelIV.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = modelIV.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q41m2LFykZpi",
        "outputId": "68711772-af75-4cd3-fb26-4b5cd30b3aaa"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "217/217 [==============================] - 55s 163ms/step - loss: 0.6823 - acc: 0.5426 - val_loss: 0.8633 - val_acc: 0.2857\n",
            "Epoch 2/20\n",
            "217/217 [==============================] - 32s 148ms/step - loss: 0.5438 - acc: 0.7260 - val_loss: 0.6464 - val_acc: 0.7143\n",
            "Epoch 3/20\n",
            "217/217 [==============================] - 42s 195ms/step - loss: 0.4200 - acc: 0.8138 - val_loss: 0.8320 - val_acc: 0.2857\n",
            "Epoch 4/20\n",
            "217/217 [==============================] - 32s 146ms/step - loss: 0.3390 - acc: 0.8568 - val_loss: 1.5982 - val_acc: 0.2857\n",
            "Epoch 5/20\n",
            "217/217 [==============================] - 29s 133ms/step - loss: 0.2897 - acc: 0.8786 - val_loss: 0.7765 - val_acc: 0.5714\n",
            "Epoch 6/20\n",
            "217/217 [==============================] - 27s 123ms/step - loss: 0.2491 - acc: 0.9011 - val_loss: 0.6813 - val_acc: 0.5714\n",
            "Epoch 7/20\n",
            "217/217 [==============================] - 36s 166ms/step - loss: 0.2151 - acc: 0.9135 - val_loss: 0.4963 - val_acc: 0.5714\n",
            "Epoch 8/20\n",
            "217/217 [==============================] - 32s 146ms/step - loss: 0.2008 - acc: 0.9184 - val_loss: 0.4610 - val_acc: 0.7143\n",
            "Epoch 9/20\n",
            "217/217 [==============================] - 34s 156ms/step - loss: 0.1882 - acc: 0.9271 - val_loss: 0.3948 - val_acc: 1.0000\n",
            "Epoch 10/20\n",
            "217/217 [==============================] - 28s 131ms/step - loss: 0.1692 - acc: 0.9327 - val_loss: 0.3334 - val_acc: 0.7143\n",
            "Epoch 11/20\n",
            "217/217 [==============================] - 38s 174ms/step - loss: 0.1601 - acc: 0.9368 - val_loss: 0.4366 - val_acc: 0.7143\n",
            "Epoch 12/20\n",
            "217/217 [==============================] - 39s 180ms/step - loss: 0.1510 - acc: 0.9430 - val_loss: 0.3799 - val_acc: 0.8571\n",
            "Epoch 13/20\n",
            "217/217 [==============================] - 28s 129ms/step - loss: 0.1426 - acc: 0.9486 - val_loss: 0.3273 - val_acc: 1.0000\n",
            "Epoch 14/20\n",
            "217/217 [==============================] - 32s 145ms/step - loss: 0.1377 - acc: 0.9466 - val_loss: 0.2426 - val_acc: 1.0000\n",
            "Epoch 15/20\n",
            "217/217 [==============================] - 44s 203ms/step - loss: 0.1251 - acc: 0.9520 - val_loss: 0.2454 - val_acc: 1.0000\n",
            "Epoch 16/20\n",
            "217/217 [==============================] - 34s 156ms/step - loss: 0.1191 - acc: 0.9556 - val_loss: 0.2842 - val_acc: 1.0000\n",
            "Epoch 17/20\n",
            "217/217 [==============================] - 31s 141ms/step - loss: 0.1158 - acc: 0.9552 - val_loss: 0.3217 - val_acc: 0.8571\n",
            "Epoch 18/20\n",
            "217/217 [==============================] - 27s 123ms/step - loss: 0.1141 - acc: 0.9578 - val_loss: 0.2454 - val_acc: 1.0000\n",
            "Epoch 19/20\n",
            "217/217 [==============================] - 32s 146ms/step - loss: 0.1087 - acc: 0.9572 - val_loss: 0.2949 - val_acc: 1.0000\n",
            "Epoch 20/20\n",
            "217/217 [==============================] - 34s 158ms/step - loss: 0.1036 - acc: 0.9624 - val_loss: 0.2542 - val_acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelIV = model_to_onnx(modelIV, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelIV.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_modelIV.SerializeToString())"
      ],
      "metadata": {
        "id": "sktDOI-NlG_q"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model IV: \n",
        "\n",
        "#-- Generate predicted y values \n",
        "prediction_column_index=modelIV.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model IV to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelIV.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfEBxq47lcRW",
        "outputId": "08f2c196-a927-4af8-d0d1-e603df3f2526"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 2s 29ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): .\n",
            "\n",
            "Your model has been submitted as model version 437\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THe above model has an accuracy of 80.01%, an f-1 score of 80.98%, a precision of 81.24% and a recall of 81.01%. I ran it for 20 epochs, used rmsprop as the optimiser and had a validation split value of 0.001. It had 5 lstm layers"
      ],
      "metadata": {
        "id": "r2cwPo7jqJjP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "SUK0FItomS3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qOyqoVwmU57",
        "outputId": "9d45edb5-1e0e-4e86-8894-4950dc5da8ee"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.9/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (23.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras_tuner) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras_tuner) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Separate validation data \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_split, x_val, y_train_split, y_val = train_test_split(\n",
        "     X_train, y_train, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "j_WrStF4mYA6"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "import keras_tuner as kt\n",
        "\n",
        "#Define model structure & parameter search space with function\n",
        "def build_model(hp):\n",
        "    modelIV = keras.Sequential()\n",
        "    modelIV.add(Embedding(10000, 16, input_length=40))\n",
        "    modelIV.add(LSTM(units=hp.Int(\"units\", min_value=32, max_value=512, step=32), #range 32-512 inclusive, minimum step between tested values is 32\n",
        "                   return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "    modelIV.add(Flatten())\n",
        "    modelIV.add(Dense(2, activation='softmax'))\n",
        "    modelIV.compile(\n",
        "        optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return modelIV\n",
        "\n",
        "#initialize the tuner (which will search through parameters)\n",
        "tuner = kt.RandomSearch(\n",
        "    hypermodel=build_model, \n",
        "    objective=\"val_accuracy\", # objective to optimize\n",
        "    max_trials=3, #max number of trials to run during search\n",
        "    executions_per_trial=1, #higher number reduces variance of results; guages model performance more accurately \n",
        "    overwrite=True,\n",
        "    directory=\"tuning_model\",\n",
        "    project_name=\"tuning_units\",\n",
        ")\n",
        "\n",
        "tuner.search(preprocessor(x_train_split), y_train_split, epochs=1, validation_data=(preprocessor(x_val), y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKzH083xmbhA",
        "outputId": "8d9700e4-f42d-4eff-a6d5-3e0311631c61"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 03m 40s]\n",
            "val_accuracy: 0.5946531891822815\n",
            "\n",
            "Best val_accuracy So Far: 0.6546242833137512\n",
            "Total elapsed time: 00h 09m 38s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with best hyperparameters\n",
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "tuned_modelIV = build_model(best_hps[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "q2Zdj_rPmtLb"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit with the entire dataset.\n",
        "tuned_modelIV.fit(x=preprocessor(X_train), y=y_train, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1wW5piQr-fX",
        "outputId": "d500d7f0-2daf-4ba2-9648-c10c53979e20"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217/217 [==============================] - 216s 970ms/step - loss: 0.6894 - accuracy: 0.5730\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f596e07bbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelIV = model_to_onnx(tuned_modelIV, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"tuned_modelIV.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_modelIV.SerializeToString())"
      ],
      "metadata": {
        "id": "_ANXNoL4mw2Z"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model IV: \n",
        "\n",
        "#-- Generate predicted y values (Model 3)\n",
        "prediction_column_index=tuned_modelIV.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 1 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"tuned_modelIV.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_mHXKi5mzNv",
        "outputId": "e5f42638-a4ee-4bfe-f3f4-ba046617a787"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 9s 148ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): .\n",
            "\n",
            "Your model has been submitted as model version 440\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model does not work as well after this with an accuracy of 65.20%, an f-1 score of\t63.21%, precision of\t69.47% and recall of\t65.23%"
      ],
      "metadata": {
        "id": "LpJaJT_ztoYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model V Transfer Learning with 20 epochs and batch size 64"
      ],
      "metadata": {
        "id": "G2zmr7yTl-6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
        "modelIII.layers[0].set_weights([embedding_matrix])\n",
        "modelIII.layers[0].trainable = False\n",
        "\n",
        "\n",
        "\n",
        "modelIII.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "giCmm6HJoSa3"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelIII.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.01)\n",
        "modelIII.save_weights('pre_trained_glove_model.h5')\n",
        "\n",
        "\n",
        "# Training data small to speed up training. Increase for better fit."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUCGW8o9pFev",
        "outputId": "2c8f1ab2-1ec8-4dd9-e346-e5b1b9c7dec0"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "108/108 [==============================] - 6s 40ms/step - loss: 0.0460 - acc: 0.9870 - val_loss: 0.5660 - val_acc: 0.8571\n",
            "Epoch 2/20\n",
            "108/108 [==============================] - 4s 35ms/step - loss: 0.0273 - acc: 0.9908 - val_loss: 0.7359 - val_acc: 0.8571\n",
            "Epoch 3/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0345 - acc: 0.9907 - val_loss: 0.8386 - val_acc: 0.8286\n",
            "Epoch 4/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0270 - acc: 0.9915 - val_loss: 0.6775 - val_acc: 0.8429\n",
            "Epoch 5/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0326 - acc: 0.9914 - val_loss: 0.5977 - val_acc: 0.8714\n",
            "Epoch 6/20\n",
            "108/108 [==============================] - 2s 22ms/step - loss: 0.0337 - acc: 0.9889 - val_loss: 1.0032 - val_acc: 0.8000\n",
            "Epoch 7/20\n",
            "108/108 [==============================] - 4s 34ms/step - loss: 0.0346 - acc: 0.9915 - val_loss: 0.6683 - val_acc: 0.8571\n",
            "Epoch 8/20\n",
            "108/108 [==============================] - 4s 36ms/step - loss: 0.0315 - acc: 0.9926 - val_loss: 0.6250 - val_acc: 0.9000\n",
            "Epoch 9/20\n",
            "108/108 [==============================] - 4s 34ms/step - loss: 0.0401 - acc: 0.9917 - val_loss: 0.6262 - val_acc: 0.8571\n",
            "Epoch 10/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0228 - acc: 0.9945 - val_loss: 0.8121 - val_acc: 0.9000\n",
            "Epoch 11/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0390 - acc: 0.9920 - val_loss: 0.9058 - val_acc: 0.8714\n",
            "Epoch 12/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0231 - acc: 0.9931 - val_loss: 1.0178 - val_acc: 0.8714\n",
            "Epoch 13/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0279 - acc: 0.9921 - val_loss: 0.7912 - val_acc: 0.8571\n",
            "Epoch 14/20\n",
            "108/108 [==============================] - 4s 34ms/step - loss: 0.0198 - acc: 0.9949 - val_loss: 0.8137 - val_acc: 0.8857\n",
            "Epoch 15/20\n",
            "108/108 [==============================] - 4s 35ms/step - loss: 0.0251 - acc: 0.9934 - val_loss: 0.9072 - val_acc: 0.8714\n",
            "Epoch 16/20\n",
            "108/108 [==============================] - 4s 34ms/step - loss: 0.0241 - acc: 0.9961 - val_loss: 1.0312 - val_acc: 0.8429\n",
            "Epoch 17/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0255 - acc: 0.9943 - val_loss: 0.7014 - val_acc: 0.9000\n",
            "Epoch 18/20\n",
            "108/108 [==============================] - 2s 22ms/step - loss: 0.0236 - acc: 0.9950 - val_loss: 0.9450 - val_acc: 0.8571\n",
            "Epoch 19/20\n",
            "108/108 [==============================] - 2s 21ms/step - loss: 0.0370 - acc: 0.9931 - val_loss: 0.8328 - val_acc: 0.8571\n",
            "Epoch 20/20\n",
            "108/108 [==============================] - 2s 22ms/step - loss: 0.0280 - acc: 0.9933 - val_loss: 0.9231 - val_acc: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelV = model_to_onnx(modelIII, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelV.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_modelV.SerializeToString())"
      ],
      "metadata": {
        "id": "q_TbjEWnqAsa"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model III: \n",
        "\n",
        "#-- Generate predicted y values.\n",
        "prediction_column_index=modelIII.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model 2 to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelV.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgnbZU4UqEt3",
        "outputId": "0b5868e8-bfb7-407e-d93b-7e39e1279ef1"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 0s 6ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): .\n",
            "\n",
            "Your model has been submitted as model version 448\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get leaderboard\n",
        "\n",
        "data = mycompetition.get_leaderboard()\n",
        "mycompetition.stylize_leaderboard(data)"
      ],
      "metadata": {
        "id": "3tgne8Swu8jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model VI 7 LSTM layers with no dropout and adam optimizer, batch size =64, 20 epochs and 0.001 validation split"
      ],
      "metadata": {
        "id": "pbLOvYbbqzId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and submit model 2 using same preprocessor (note that you could save a new preprocessor, but we will use the same one for this example).\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
        "\n",
        "modelVI = Sequential()\n",
        "modelVI.add(Embedding(10000, 16, input_length=40))\n",
        "modelVI.add(LSTM(32, return_sequences=True, dropout=0))\n",
        "modelVI.add(LSTM(32, return_sequences=True))\n",
        "modelVI.add(LSTM(32, return_sequences=True))\n",
        "modelVI.add(LSTM(32, return_sequences=True))\n",
        "modelVI.add(LSTM(32, return_sequences=True))\n",
        "modelVI.add(LSTM(32, return_sequences=True))\n",
        "modelVI.add(LSTM(32, dropout=0))\n",
        "modelVI.add(Flatten())\n",
        "modelVI.add(Dense(2, activation='softmax'))\n",
        "\n",
        "modelVI.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = modelVI.fit(preprocessor(X_train), y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=64,\n",
        "                    validation_split=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-y4z7wMouFGf",
        "outputId": "fc5182bd-9180-4318-9931-871f2813657d"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "109/109 [==============================] - 47s 283ms/step - loss: 0.6923 - acc: 0.5199 - val_loss: 0.7562 - val_acc: 0.2857\n",
            "Epoch 2/20\n",
            "109/109 [==============================] - 25s 228ms/step - loss: 0.6126 - acc: 0.6511 - val_loss: 0.6341 - val_acc: 0.8571\n",
            "Epoch 3/20\n",
            "109/109 [==============================] - 31s 286ms/step - loss: 0.3895 - acc: 0.8264 - val_loss: 0.7425 - val_acc: 0.2857\n",
            "Epoch 4/20\n",
            "109/109 [==============================] - 30s 273ms/step - loss: 0.2449 - acc: 0.9019 - val_loss: 0.7927 - val_acc: 0.5714\n",
            "Epoch 5/20\n",
            "109/109 [==============================] - 23s 207ms/step - loss: 0.1650 - acc: 0.9377 - val_loss: 0.9012 - val_acc: 0.5714\n",
            "Epoch 6/20\n",
            "109/109 [==============================] - 30s 273ms/step - loss: 0.1329 - acc: 0.9550 - val_loss: 1.2925 - val_acc: 0.7143\n",
            "Epoch 7/20\n",
            "109/109 [==============================] - 31s 283ms/step - loss: 0.1037 - acc: 0.9657 - val_loss: 1.1936 - val_acc: 0.7143\n",
            "Epoch 8/20\n",
            "109/109 [==============================] - 29s 270ms/step - loss: 0.0813 - acc: 0.9776 - val_loss: 1.3583 - val_acc: 0.7143\n",
            "Epoch 9/20\n",
            "109/109 [==============================] - 29s 271ms/step - loss: 0.0644 - acc: 0.9815 - val_loss: 1.3929 - val_acc: 0.7143\n",
            "Epoch 10/20\n",
            "109/109 [==============================] - 30s 276ms/step - loss: 0.0522 - acc: 0.9839 - val_loss: 1.1895 - val_acc: 0.7143\n",
            "Epoch 11/20\n",
            "109/109 [==============================] - 32s 298ms/step - loss: 0.0459 - acc: 0.9861 - val_loss: 1.1504 - val_acc: 0.7143\n",
            "Epoch 12/20\n",
            "109/109 [==============================] - 27s 251ms/step - loss: 0.0361 - acc: 0.9903 - val_loss: 0.6943 - val_acc: 0.8571\n",
            "Epoch 13/20\n",
            "109/109 [==============================] - 37s 343ms/step - loss: 0.0334 - acc: 0.9905 - val_loss: 1.2486 - val_acc: 0.7143\n",
            "Epoch 14/20\n",
            "109/109 [==============================] - 28s 261ms/step - loss: 0.0280 - acc: 0.9923 - val_loss: 1.7422 - val_acc: 0.7143\n",
            "Epoch 15/20\n",
            "109/109 [==============================] - 23s 207ms/step - loss: 0.0229 - acc: 0.9952 - val_loss: 1.1801 - val_acc: 0.8571\n",
            "Epoch 16/20\n",
            "109/109 [==============================] - 23s 210ms/step - loss: 0.0233 - acc: 0.9935 - val_loss: 1.7194 - val_acc: 0.7143\n",
            "Epoch 17/20\n",
            "109/109 [==============================] - 23s 215ms/step - loss: 0.0241 - acc: 0.9939 - val_loss: 1.8683 - val_acc: 0.5714\n",
            "Epoch 18/20\n",
            "109/109 [==============================] - 25s 228ms/step - loss: 0.0236 - acc: 0.9933 - val_loss: 1.6551 - val_acc: 0.5714\n",
            "Epoch 19/20\n",
            "109/109 [==============================] - 24s 217ms/step - loss: 0.0160 - acc: 0.9962 - val_loss: 1.4581 - val_acc: 0.7143\n",
            "Epoch 20/20\n",
            "109/109 [==============================] - 26s 242ms/step - loss: 0.0143 - acc: 0.9970 - val_loss: 1.6157 - val_acc: 0.7143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save keras model to local ONNX file\n",
        "from aimodelshare.aimsonnx import model_to_onnx\n",
        "\n",
        "onnx_modelVI = model_to_onnx(modelVI, framework='keras',\n",
        "                          transfer_learning=False,\n",
        "                          deep_learning=True)\n",
        "\n",
        "with open(\"modelVI.onnx\", \"wb\") as f:\n",
        "    f.write(onnx_modelVI.SerializeToString())"
      ],
      "metadata": {
        "id": "S35JkZ2CvYkk"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Submit Model VI: \n",
        "\n",
        "#-- Generate predicted y values \n",
        "prediction_column_index=modelVI.predict(preprocessor(X_test)).argmax(axis=1)\n",
        "\n",
        "# extract correct prediction labels \n",
        "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
        "\n",
        "# Submit Model IV to Competition Leaderboard\n",
        "mycompetition.submit_model(model_filepath = \"modelVI.onnx\",\n",
        "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
        "                                 prediction_submission=prediction_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We2nAWhFvg3-",
        "outputId": "35e3a48b-1e42-449f-d277-ce1544b92ff9"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57/57 [==============================] - 2s 38ms/step\n",
            "Insert search tags to help users find your model (optional): .\n",
            "Provide any useful notes about your model (optional): .\n",
            "\n",
            "Your model has been submitted as model version 451\n",
            "\n",
            "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
            "\n",
            " https://www.modelshare.org/detail/model:2763\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FINAL COMMENTS"
      ],
      "metadata": {
        "id": "Y_R5lPb87-Ib"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO summarize alL of my models,\n",
        "\n",
        "Model 1:\n",
        "5 LSTM layers with 32 neurons each, batch size=32, validation split = 0.2, 1 epoch, optimiser= rmsprop.\n",
        "It has an accuracy of 50.82%, an f-1 score of\t35.23%, precision of\t75.19% and recall of\t50.88%\n",
        "\n",
        "MODEL 2:\n",
        "MODEL WITH AN EMBEDDED LAYER AND CONV 1 D LAYERS.\n",
        "It has 2 layers with 64 neurons, 2 layers 32 neurons, Max pooling, 2 layers 16 neurons, Global average pooling. It uses the optimizer rmsprop, has a batch size =32 and validation split = 0.2. This model has an accuracy of 49.95%, an f-1 score of\t33.31%, precision of\t24.97% and recall of\t50.00%\n",
        "\n",
        "Model 3:\n",
        "My best model before discussion- I used transfer learning with glove embeddings. I applied these weights on the conv 1 d model which had 2 layers of 64 neurons, 2 layers of 32 neurons and eventually 2 layers of 16 neurons. I ran 10 epochs, had a batch_size=32,validation_split=0.01, optimizer='rmsprop' and had an accuracy of 79.69%, an f-1 score of79.66%,, precision of 79.89% and recall of 79.70%\n",
        "\n",
        "Model 4:\n",
        "My best model overall- It has 5 lstm layers,each layer has 32 neurons. I ran it for 20 epochs, it had a batch size of 32, validation split of 0.001 and used the optimizer rmsprop.This model had the highest scores and best results. \n",
        "It had an accuracy of 81.01%, an f-1 score of\t80.98%, precision of\t81.24% and recall of\t81.01%. However, after using best parameters to build the model, we had an accuracy of 65.20%, an f-1 score of 63.21%, precision of 69.47% and recall of 65.23% \n",
        "\n",
        "Model 5:\n",
        "This model is similar to the other transfer learning model- model3. Since that was my best model before discussion, I wanted to incorporate some changes to see how much better it could be. I increased the batch size from 32 to 64 and ran it for 20 epochs. It is a transfer learning model with glove embeddings and is applied to the same conv 1 d model(model 2) as model 3. This however reduces the model's perfromance with an accuracy score of 77.61%, an f-1 score of 77.58%, precision of 77.73% and recall of 77.60%\n",
        "\n",
        "Model 6:\n",
        "Since my previous LSTM model (Model 4) was my best model, I wanted to change a few aspects about the model and check if it was still as good. I changed the dropout from 0.2 to none. I added two more LSTM layers, ran it for 20 epochs, with a batch size of 64 and a validation split og 0.001. Surprisingly, it underperformed and had an accuracy score of75.41%, f-1 score of\t75.41%, precision of 75.42% and recall of\t75.41%."
      ],
      "metadata": {
        "id": "QLfR8hshxLJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link to github\n",
        "https://github.com/arushisaranath/Movie-Review-Sentiment-Analysis-Model"
      ],
      "metadata": {
        "id": "o5iuypGzK455"
      }
    }
  ]
}
